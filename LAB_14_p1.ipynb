{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2497baf-b8eb-4b09-b29a-b6976388a019",
   "metadata": {},
   "source": [
    "## Q.1 Implement the forward propagation for a two hidden layer network for m-samples, n-features as we discussed in class. Initialize the weights randomly. Use the data from the previous labs like logistic regression. You can choose the number of neurons in the hidden layer and use sigmoid activation function.Report the evaluation metrics for the network.  Also use other non-linear activation functions like ReLU and Tanh. Report the loss using both MSE and Cross Entropy.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3eba6299-7851-4d3e-8ace-d32d21d20285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "def softmax(x):\n",
    "    x_max = np.max(x, axis=0, keepdims=True)\n",
    "    e_x = np.exp(x - x_max)\n",
    "    return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
    "    \n",
    "# activation function so that we can change it\n",
    "def activation(x, active):\n",
    "    if active == \"sigmoid\":\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    elif active == \"relu\":\n",
    "        return np.maximum(0, x)\n",
    "    elif active == \"tanh\":\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c1ecc27-2588-4510-ad63-0d5dfb1484e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "\n",
    "def init_parameters(input_size, hidden_size1, hidden_size2, output_size):\n",
    "    np.random.seed(0)\n",
    "    parameters = {}\n",
    "    parameters['W1'] = np.random.randn(hidden_size1, input_size) \n",
    "    parameters['b1'] = np.zeros((hidden_size1, 1))\n",
    "    parameters['W2'] = np.random.randn(hidden_size2, hidden_size1)\n",
    "    parameters['b2'] = np.zeros((hidden_size2, 1))\n",
    "    parameters['W3'] = np.random.randn(output_size, hidden_size2)\n",
    "    parameters['b3'] = np.zeros((output_size, 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ee1f0e3-1908-485f-9615-f08a8dee3224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        x1     x2  label\n",
      "0    7.395  7.638      1\n",
      "1    4.987  6.485      1\n",
      "2    5.358  6.499      1\n",
      "3    2.036  2.380      0\n",
      "4    5.956  7.378      1\n",
      "..     ...    ...    ...\n",
      "495  0.304  1.608      0\n",
      "496  6.140  4.261      1\n",
      "497  6.579  6.231      1\n",
      "498  2.555  0.446      0\n",
      "499  2.148  0.852      0\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Logistic_regression_ls.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "909d5457-b9c9-4af5-8ccf-9ad597226f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 500)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Take input and labels from file\n",
    "\n",
    "X = df[['x1', 'x2']].values\n",
    "y = df['label'].values.reshape(-1, 1)\n",
    "X = X.T # Transpose to multiply it with W\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d0ed76e7-ba56-4967-bce3-f8755db428a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation_fn):\n",
    "    \n",
    "    # get parameters from dict\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    # Forward propagation\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = activation(Z1, activation_fn)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = activation(Z2, activation_fn)\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    y_pred = sigmoid(Z3)\n",
    "    \n",
    "    # updated_dict = {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2, 'Z3': Z3, 'A3': A3}\n",
    "    \n",
    "    return y_pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab041bda-c1a8-4b2b-a74e-e43c2577051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[0]\n",
    "hidden_size1 = 10\n",
    "hidden_size2 = 10\n",
    "output_size = 1\n",
    "\n",
    "# initialize parameters\n",
    "parameters = init_parameters(input_size, hidden_size1, hidden_size2, output_size)\n",
    "# print(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e501f717-2ee8-43b3-9d26-f825cec3432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward prop for different activations\n",
    "\n",
    "y_pred1 = forward_propagation(X, parameters, activation_fn=\"sigmoid\")\n",
    "y_pred2 = forward_propagation(X, parameters, activation_fn=\"relu\")\n",
    "y_pred3 = forward_propagation(X, parameters, activation_fn=\"tanh\")\n",
    "\n",
    "# print(y_pred1)\n",
    "# print(y_pred2)\n",
    "# print(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93e6886c-957d-4ae3-a3b9-9b3aa6a098ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "# Cross entropy\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15  # to prevent log(0) cases\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3557c395-e1b4-4f42-9c71-ec27c2f45abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Using Sigmoid activation function 0.41988458946454016\n",
      "MSE Using Relu activation function 0.4999971182583223\n",
      "MSE Using tanh activation function 0.36545125350493163\n"
     ]
    }
   ],
   "source": [
    "# print(\"Output predictions (A3) shape:\\n\", y_pred.shape)\n",
    "\n",
    "MSE1 = mean_squared_error(y, y_pred1)\n",
    "MSE2 = mean_squared_error(y, y_pred2)\n",
    "MSE3 = mean_squared_error(y, y_pred3)\n",
    "\n",
    "print('MSE Using Sigmoid activation function', MSE1)\n",
    "print('MSE Using Relu activation function', MSE2)\n",
    "print('MSE Using tanh activation function', MSE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac3f7ae6-e874-4731-a17d-b14aef889b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy loss Using Sigmoid activation function 1.263801246419863\n",
      "Cross Entropy loss Using Relu activation function 14.895921238585863\n",
      "Cross Entropy loss Using tanh activation function 1.0287023477610566\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Loss(CEL)\n",
    "\n",
    "CEL1 = binary_cross_entropy(y, y_pred1)\n",
    "CEL2 = binary_cross_entropy(y, y_pred2)\n",
    "CEL3 = binary_cross_entropy(y, y_pred3)\n",
    "\n",
    "print('Cross Entropy loss Using Sigmoid activation function', CEL1)\n",
    "print('Cross Entropy loss Using Relu activation function', CEL2)\n",
    "print('Cross Entropy loss Using tanh activation function', CEL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "23136782-8ce7-429f-9d4c-e45233a9a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(output_probs, threshold=0.5):\n",
    "    # Convert output probabilities to binary labels\n",
    "    return (output_probs >= threshold).astype(int)\n",
    "\n",
    "# Convert output probabilities to binary labels using a threshold = 0.5\n",
    "y_pred_labels1 = predict_labels(y_pred1)\n",
    "y_pred_labels2 = predict_labels(y_pred2)\n",
    "y_pred_labels3 = predict_labels(y_pred3)\n",
    "\n",
    "# print(y_pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e0e0fc8-fbc7-43bd-89ca-4366a9e41572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric Using Sigmoid activation function:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def evaluation_metric(y_true, y_pred):\n",
    "    # accuracy\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # precision\n",
    "    precision = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1)\n",
    "    # recall\n",
    "    recall = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_true == 1)\n",
    "    # F1-score\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "# Evaluation metric of the model\n",
    "accuracy1, precision1, recall1, f1_score1 = evaluation_metric(y, y_pred_labels1)\n",
    "print('Evaluation metric Using Sigmoid activation function:')\n",
    "\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print(\"Precision:\", precision1)\n",
    "print(\"Recall:\", recall1)\n",
    "print(\"F1 Score:\", f1_score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7bd6e129-7b9a-4f7c-ba1d-9d5363d874fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric Using Relu activation function:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "accuracy2, precision2, recall2, f1_score2 = evaluation_metric(y, y_pred_labels2)\n",
    "print('Evaluation metric Using Relu activation function:')\n",
    "\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"Recall:\", recall2)\n",
    "print(\"F1 Score:\", f1_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "208cca1d-9111-4b70-ac86-848ea5df3d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric Using tanh activation function:\n",
      "Accuracy: 0.504\n",
      "Precision: 0.5020080321285141\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6684491978609626\n"
     ]
    }
   ],
   "source": [
    "accuracy3, precision3, recall3, f1_score3 = evaluation_metric(y, y_pred_labels3)\n",
    "print('Evaluation metric Using tanh activation function:')\n",
    "\n",
    "print(\"Accuracy:\", accuracy3)\n",
    "print(\"Precision:\", precision3)\n",
    "print(\"Recall:\", recall3)\n",
    "print(\"F1 Score:\", f1_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8afff-e0c0-448b-8ffa-a58fd8e9d847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
